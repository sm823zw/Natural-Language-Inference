{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0f8eb42e5489e27d1639c09f8459f37d2bbca2e9654832ca6636f5f200c1be13b",
   "display_name": "Python 3.8.8 64-bit ('MLSPproj': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f8eb42e5489e27d1639c09f8459f37d2bbca2e9654832ca6636f5f200c1be13b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from get_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data()\n",
    "train_data = data[:3]\n",
    "test_data = data[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, embed_matrix = preprocess_traindata(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding =  tf.keras.layers.Embedding(embed_matrix.shape[0], output_dim=EMBEDDING_DIM, weights=[embed_matrix], input_length=MAX_SEQ_LEN, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layers and its shapes for premise and hypothesis\n",
    "premise = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "hypothesis = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise.shape, hypothesis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the premise and hypothesis\n",
    "premise_embedded = embedding(premise)\n",
    "hypothesis_embedded = embedding(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_embedded.shape, hypothesis_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a time distributed translation layer for better performance\n",
    "# Time distributed layer applies the same Dense layer to each temporal slice of input\n",
    "translation = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the translation layer\n",
    "premise_translated = translation(premise_embedded)\n",
    "hypothesis_translated = translation(hypothesis_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_translated.shape, hypothesis_translated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM layer\n",
    "BiLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bidirectional LSTM layer\n",
    "premise_BiLSTM = BiLSTM(premise_translated)\n",
    "hypothesis_BiLSTM = BiLSTM(hypothesis_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_BiLSTM.shape, hypothesis_BiLSTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Batch normalization\n",
    "premise_normalized = tf.keras.layers.BatchNormalization()(premise_BiLSTM)\n",
    "hypothesis_normalized = tf.keras.layers.BatchNormalization()(hypothesis_BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the normalized premise and hypothesis and apply a dropout layer\n",
    "train_input = tf.keras.layers.concatenate([premise_normalized, hypothesis_normalized])\n",
    "train_input = tf.keras.layers.Dropout(0.2)(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = tf.keras.regularizers.l2(l2=0)\n",
    "\n",
    "train_input = tf.keras.layers.Dense(200, activation='tanh', kernel_regularizer=lam)(train_input)\n",
    "train_input = tf.keras.layers.Dropout(0.2)(train_input)\n",
    "train_input = tf.keras.layers.BatchNormalization()(train_input)\n",
    "\n",
    "train_input = tf.keras.layers.Dense(200, activation='tanh', kernel_regularizer=lam)(train_input)\n",
    "train_input = tf.keras.layers.Dropout(0.2)(train_input)\n",
    "train_input = tf.keras.layers.BatchNormalization()(train_input)\n",
    "\n",
    "train_input = tf.keras.layers.Dense(200, activation='tanh', kernel_regularizer=lam)(train_input)\n",
    "train_input = tf.keras.layers.Dropout(0.2)(train_input)\n",
    "train_input = tf.keras.layers.BatchNormalization()(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output Dense layer\n",
    "prediction = tf.keras.layers.Dense(3, activation='softmax')(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the complete model\n",
    "model = tf.keras.models.Model(inputs=[premise, hypothesis], outputs=prediction)\n",
    "\n",
    "# Choosing an optimizer\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "# Compile the model and print out the model summary\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=4, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "# ModelCheckpoint callback to save the model with best performance\n",
    "# A temporary file is created to which the intermediate model weights are stored\n",
    "_, tmpfn = tempfile.mkstemp()\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(tmpfn, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(x=[train_data[0], train_data[1]], y=train_data[2], batch_size=256, epochs=5, validation_split=0.02, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}